{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "dataframe = pd.read_csv(\"tese-regression-model-v1\\dataset_final.csv\")\n",
    "dataset = dataframe.values\n",
    "\n",
    "#dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "X = dataset[:,35:39]\n",
    "y = dataset[:,0:35]\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_poly = poly.fit_transform(X) #we now have a feature vector with 15 rows instead of only 4\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "x_scaled = standard_scaler.fit_transform(X_poly)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    percentage = 0.3\n",
    "    \n",
    "    pred_class = y_pred[..., 0:2]\n",
    "    true_class = tf.argmax(y_true[..., 0:2], -1)\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_class, logits=pred_class)\n",
    "    \n",
    "    loss_reg1 = K.mean(K.square(y_pred[...,2:17] - y_true[...,2:17]), axis=-1)\n",
    "    loss_reg2 = K.mean(K.square(y_pred[...,17:35] - y_true[...,17:35]), axis=-1)\n",
    "    \n",
    "    loss = percentage*loss_class + (1-percentage)*(loss_reg1*y_true[..., 0] + loss_reg2*y_true[..., 1])\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense    \n",
    "from keras import regularizers\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=15, kernel_initializer='normal',  activation='relu'))\n",
    "    model.add(Dense(35, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss=custom_loss, optimizer='adam') \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2018-02-22 22:51:40.257173\n",
      "Elapsed Time: 0:00:34.328197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_scaled,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = seed)\n",
    "\n",
    "model = baseline_model()\n",
    "\n",
    "#Starting Time\n",
    "start_time = datetime.now()\n",
    "print('Start Time:', start_time)\n",
    "\n",
    "history = model.fit(x_scaled, \n",
    "                    y_scaled, \n",
    "                    validation_split = 0.33,\n",
    "                    epochs = 500, \n",
    "                    batch_size= 128, \n",
    "                    verbose = 0)\n",
    "\n",
    "stop_time = datetime.now()\n",
    "\n",
    "elapsed_time = stop_time - start_time\n",
    "print('Elapsed Time:', elapsed_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.00000000e-06   6.99000000e-05   2.48000000e-05\n",
      "   3.70000000e-06   6.40000000e-06   9.59000000e-05   5.00000000e+00\n",
      "   7.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "   3.00000000e+00   8.90000000e-07   7.70000000e-07   7.80000000e-07\n",
      "   8.90000000e-07   3.00000000e-07   5.50000000e-07]\n",
      "[ -7.12387991e+00   6.82507944e+00   1.80346506e-05   3.39156795e-05\n",
      "   1.22853480e-05  -6.93475522e-05   1.71631109e-06   2.90794310e-06\n",
      "  -7.30882130e-06  -1.00329100e-06   4.00879717e+00   1.10588169e+01\n",
      "   2.03056788e+00   3.90773315e+01  -4.85577164e+01  -5.16889741e-05\n",
      "   1.64866371e+01   1.00528484e-06   7.09566593e-05   2.30305977e-05\n",
      "   1.26298246e-05   6.19859247e-06   7.95038213e-05   3.47509694e+00\n",
      "   4.85650253e+00   4.04682970e+00   4.10836172e+00   3.65314960e+00\n",
      "   2.11933708e+00   9.30786655e-07   8.25970858e-07   7.78429410e-07\n",
      "   8.81413655e-07   3.12613878e-07   5.76664718e-07]\n",
      "[-7.12387991  6.82507944  0.9017325   0.29262882  0.2353515  -0.60407275\n",
      "  0.24105492  0.47130358 -0.73088211 -0.10881682  0.5726853   1.00534701\n",
      "  0.01310044  0.19538666 -0.24278858 -0.51688975  0.08326585  0.83773738\n",
      "  0.70956659  0.23030597  0.21049708  0.2213783   0.79503822  0.49644241\n",
      "  0.60706282  0.50585371  0.51354522  0.4566437   0.26491714  0.99019855\n",
      "  0.87869239  0.82811642  0.93767411  0.34734875  0.64073855]\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(x_scaled)\n",
    "predicted_inverse = scaler.inverse_transform(y_proba)\n",
    "print(y[2000])\n",
    "print(predicted_inverse[2000])\n",
    "print(y_proba[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = y_proba[...,:2].argmax(axis=-1)\n",
    "print(y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=numpy.nan)\n",
    "sess = tf.InteractiveSession()\n",
    "a = tf.nn.softmax(logits=y_proba[...,:2], dim=-1)\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[730])\n",
    "print(y_proba[730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
